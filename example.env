# common
HOST=localhost
LOCATION_FILE=https://github.com/ppkgtmm/location/raw/main/states_provinces.csv

# data generation
SEED=42
SEED_DIR=seeds/

# mysql db
DB_HOST=${HOST}
DB_HOST_INTERNAL=mysql
DB_PORT=3306
DB_USER=root
DB_PASSWORD=<TO BE FILLED>
MYSQL_ROOT_PASSWORD=${DB_PASSWORD}
OLTP_DB=oltp_hotel
DWH_DB=dwh_hotel
USERS_TABLE=users
GUESTS_TABLE=guests
ADDONS_TABLE=addons
ROOMTYPES_TABLE=roomtypes
ROOMS_TABLE=rooms
BOOKINGS_TABLE=bookings
BOOKING_ROOMS_TABLE=booking_rooms
BOOKING_ADDONS_TABLE=booking_addons
DIM_DATE_TABLE=dim_date
DIM_ROOMTYPE_TABLE=dim_roomtype
DIM_ADDON_TABLE=dim_addon
DIM_GUEST_TABLE=dim_guest
DIM_LOCATION_TABLE=dim_location
FCT_BOOKING_TABLE=fct_bookings
FCT_AMENITIES_TABLE=fct_amenities
FULL_PICTURE_TABLE=full_picture
RAW_ROOM_TABLE=stg_room
RAW_GUEST_TABLE=stg_guest
RAW_BOOKING_TABLE=stg_booking
RAW_BOOKING_ROOM_TABLE=stg_booking_room
RAW_BOOKING_ADDON_TABLE=stg_booking_addon
DT_FORMAT=%Y%m%d%H%M%S
FACT_LOAD_DAG_NAME=process_facts
FULL_PICTURE_DAG_NAME=process_full_picture
CLEAN_UP_DAG_NAME=clean_up

# mysql user for debezium
DBZ_USER=dbz_user
DBZ_PASSWORD=<TO BE FILLED>
DBZ_PREVILLAGES=SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT
DBZ_CONNECTOR=hotel_reader

# zookeeper
ZOOKEEPER_HOST_INTERNAL=zookeeper
ZOOKEEPER_PORT=2181
ZOOKEEPER_CLIENT_PORT=${ZOOKEEPER_PORT}
ZOOKEEPER_TICK_TIME=2000

# kafka broker common
KAFKA_HOST_INTERNAL=broker
KAFKA_PORT_INTERNAL=9092
KAFKA_BOOTSTRAP_SERVERS_INTERNAL=${KAFKA_HOST_INTERNAL}:${KAFKA_PORT_INTERNAL}

# schema registry
SCHEMA_REGISTRY_HOST_INTERNAL=schema-registry
REGISTRY_PORT=8081
SCHEMA_REGISTRY_HOST_NAME=${SCHEMA_REGISTRY_HOST_INTERNAL}
SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=PLAINTEXT://${KAFKA_BOOTSTRAP_SERVERS_INTERNAL}
SCHEMA_REGISTRY_URL_INTERNAL=http://${SCHEMA_REGISTRY_HOST_INTERNAL}:${REGISTRY_PORT}
SCHEMA_REGISTRY_LISTENERS=${SCHEMA_REGISTRY_URL_INTERNAL}
SCHEMA_REGISTRY_URL=http://${HOST}:${REGISTRY_PORT}

# kafka broker
BROKER_PORT=29092
KAFKA_BOOTSTRAP_SERVERS=${HOST}:${BROKER_PORT}
KAFKA_BROKER_ID=1
KAFKA_ZOOKEEPER_CONNECT=${ZOOKEEPER_HOST_INTERNAL}:${ZOOKEEPER_PORT}
KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
KAFKA_ADVERTISED_LISTENERS=INSIDE://${KAFKA_BOOTSTRAP_SERVERS_INTERNAL},OUTSIDE://${KAFKA_BOOTSTRAP_SERVERS}
KAFKA_INTER_BROKER_LISTENER_NAME=INSIDE
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR=1
KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR=1
KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL=${SCHEMA_REGISTRY_URL_INTERNAL}
KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1

# kafka connect
CONNECT_HOST=${HOST}
CONNECT_HOST_INTERNAL=kafka-connect
CONNECT_REST_PORT=8083
KAFKA_CONNECT_SERVER=http://${CONNECT_HOST}:${CONNECT_REST_PORT}
KAFKA_CONNECT_SERVER_INTERNAL=http://${CONNECT_HOST_INTERNAL}:${CONNECT_REST_PORT}
CONNECT_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS_INTERNAL}
CONNECT_GROUP_ID=${CONNECT_HOST_INTERNAL}
CONNECT_CONFIG_STORAGE_TOPIC=hotel-config
CONNECT_OFFSET_STORAGE_TOPIC=hotel-offset
CONNECT_STATUS_STORAGE_TOPIC=hotel-status
CONNECT_KEY_CONVERTER=org.apache.kafka.connect.storage.StringConverter
CONNECT_VALUE_CONVERTER=io.confluent.connect.avro.AvroConverter
CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL=${SCHEMA_REGISTRY_URL_INTERNAL}
CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1
CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1
CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1
CONNECT_REST_ADVERTISED_HOST_NAME=${CONNECT_HOST_INTERNAL}
CONNECT_PLUGIN_PATH=/usr/share/confluent-hub-components/
CONNECT_INTERNAL_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
CONNECT_INTERNAL_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
CONNECT_INTERNAL_KEY_CONVERTER_SCHEMAS_ENABLE=false
CONNECT_INTERNAL_VALUE_CONVERTER_SCHEMAS_ENABLE=false

# processors
PROCESSOR_HOST_INTERNAL=stream-processor

# airflow
POSTGRES_HOST_INTERNAL=postgres
INIT_HOST_INTERNAL=airflow-init
SCHEDULER_HOST_INTERNAL=airflow-scheduler
WEBSERVER_HOST_INTERNAL=airflow-webserver
AIRFLOW_VERSION=2.7.1
POSTGRES_USER=airflow
POSTGRES_DB=airflow
POSTGRES_PASSWORD=<TO BE FILLED>
AIRFLOW_DATABASE_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST_INTERNAL}/${POSTGRES_DB}
AIRFLOW_ADMIN_USERNAME=admin
AIRFLOW_ADMIN_PASSWORD=<TO BE FILLED>
AIRFLOW_HOME=/airflow
DAGS_FOLDER=${AIRFLOW_HOME}/dags
AIRFLOW__CORE__DAGS_FOLDER=${DAGS_FOLDER}
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__WEBSERVER__SECRET_KEY=<TO BE FILLED>
AIRFLOW_DWH_CONN_ID=dwh_db_conn
AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.session,airflow.api.auth.backend.basic_auth
PYTHON_VERSION=3.9
WEBSERVER_PORT=8080

GEO_JSON_FILE=https://github.com/ppkgtmm/location/raw/main/states_provinces.json

SUPERSET_PORT=8088
SUPERSET_ADMIN_USERNAME=admin
SUPERSET_ADMIN_PASSWORD=<TO BE FILLED>
SUPERSET_SECRET_KEY=<TO BE FILLED>
